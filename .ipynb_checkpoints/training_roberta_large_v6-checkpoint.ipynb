{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b8830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import pickle5\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2963fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic random seed\n",
    "import os \n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "def seedBasic(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# tensorflow random seed \n",
    "import tensorflow as tf \n",
    "def seedTF(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "# torch random seed\n",
    "import torch\n",
    "def seedTorch(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + tensorflow + torch \n",
    "def seedEverything(seed=42):\n",
    "    seedBasic(seed)\n",
    "    seedTF(seed)\n",
    "    seedTorch(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c63511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams, word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def clean_text(tmp):\n",
    "    soup = BeautifulSoup(tmp)\n",
    "    text = soup.get_text(separator=\" \").strip()\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
    "    text = re.sub(r'\\t\\s*\\t', ' ', text)\n",
    "    text = re.sub(r'\\xa0', ' ', text)\n",
    "#     text = nlp(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295bb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global input_dir, output_dir, model_name, model_type, criteria, description, test_project, data_pid, title\n",
    "\n",
    "input_dir = './input_data/'\n",
    "output_dir = './output_models_v6/'\n",
    "\n",
    "model_name = 'roberta-large'\n",
    "model_type = 'roberta_v6'\n",
    "\n",
    "with open(input_dir + 'data_criteria_v6.pk5', 'rb') as f:\n",
    "    criteria = pickle5.load(f)\n",
    "with open(input_dir + 'data_description_v6.pk5', 'rb') as f:\n",
    "    description = pickle5.load(f)\n",
    "    \n",
    "import pickle\n",
    "with open('./evaluation/test_label.pkl', 'rb') as f:\n",
    "    test_label = pickle.load(f)\n",
    "test_project = list(test_label.keys())    \n",
    "\n",
    "criteria = {k: x for k, x in criteria.items() if k not in test_project}\n",
    "description = {k: x for k, x in description.items() if k not in test_project}\n",
    "\n",
    "data_pid = np.unique(list(criteria.keys()) + list(description.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149ccec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = pd.read_csv(input_dir + 'project_entity.csv', lineterminator='\\n', usecols = [0,1], header = None)\n",
    "title = {}\n",
    "for i in range(len(title_data)):\n",
    "    p = title_data.iloc[i, 0]\n",
    "    t = title_data.iloc[i, 1]\n",
    "    if (t!=t)|(t is None):\n",
    "        t = ''\n",
    "    title[p] = t\n",
    "    \n",
    "for k,v in criteria.items():\n",
    "    if len(v[0]) > 0:\n",
    "        criteria[k] = [v[0] + [title[k]], v[1]]\n",
    "    else:\n",
    "        criteria[k] = [[''], []]\n",
    "for k,v in description.items():\n",
    "    if len(v[0]) > 0:\n",
    "        description[k] = [v[0] + [title[k]], v[1]]\n",
    "    else:\n",
    "        description[k] = [[''], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ea48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from adamp import SGDP,AdamP\n",
    "\n",
    "global tokenizer, device\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space = True)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31196b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationData(Dataset):\n",
    "    def __init__(self, select_pid):\n",
    "        self.select_pid = select_pid\n",
    "        self.null = [[''], []]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.select_pid)\n",
    "    \n",
    "    def mark_text(self, x):\n",
    "        text = x[0]\n",
    "        mark = x[1]\n",
    "        st_marks = np.array([x[1] for x in mark])\n",
    "        ed_marks = np.array([x[2] for x in mark])\n",
    "        scores = np.array([x[-1] for x in mark])\n",
    "        ed_marks = ed_marks[np.argsort(st_marks)]\n",
    "        scores = scores[np.argsort(st_marks)]\n",
    "        st_marks = np.sort(st_marks)\n",
    "\n",
    "        marked_text = []\n",
    "        prev_ed = 0\n",
    "        for (st, ed) in zip(st_marks, ed_marks):\n",
    "            marked_text += text[prev_ed:st] + [tokenizer.mask_token] + \\\n",
    "                            text[st:ed] + [tokenizer.mask_token]\n",
    "            prev_ed = ed\n",
    "        marked_text += text[prev_ed:]\n",
    "\n",
    "        inputs = tokenizer(marked_text, \n",
    "                           padding = True,\n",
    "                           is_split_into_words = True,\n",
    "                           truncation = True,\n",
    "                           return_tensors = 'pt')\n",
    "\n",
    "        n =  len(inputs['input_ids'][0])\n",
    "        end_label = torch.zeros((1, n))\n",
    "        start_label = torch.zeros((1, n))\n",
    "\n",
    "        label_position = np.where(inputs['input_ids'].numpy() == tokenizer.mask_token_id)[1]\n",
    "\n",
    "        if len(label_position) > 0:\n",
    "            if len(label_position) % 2 == 1:\n",
    "                label_position = label_position[:-1]\n",
    "            for k, i in enumerate(np.arange(0, len(label_position), 2)):\n",
    "                st = label_position[i]\n",
    "                ed = label_position[i + 1]\n",
    "                end_label[:, (ed - 1)] = float(scores[k] > 0.9)\n",
    "                start_label[:, (st + 1)] = float(scores[k] > 0.9)\n",
    "\n",
    "        mark_mask = inputs['input_ids'] != tokenizer.mask_token_id\n",
    "\n",
    "        start_label = start_label[mark_mask]\n",
    "        end_label = end_label[mark_mask]\n",
    "        inputs = {k: v[mark_mask] for k,v in inputs.items()}\n",
    "        \n",
    "        return inputs, start_label, end_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.select_pid[idx]\n",
    "        sample_c, sample_d = criteria.get(pid), description.get(pid)\n",
    "        sample_c = sample_c if sample_c is not None else self.null\n",
    "        sample_d = sample_d if sample_d is not None else self.null\n",
    "        \n",
    "        c_inputs, c_st, c_ed = self.mark_text(sample_c)\n",
    "        d_inputs, d_st, d_ed = self.mark_text(sample_d)\n",
    "        \n",
    "        return [c_inputs, c_st, c_ed], [d_inputs, d_st, d_ed]\n",
    "    \n",
    "def padding(batch):\n",
    "    lengths = [len(x[-1]) for x in batch]\n",
    "    max_len = max(lengths)\n",
    "    batch_input_ids, batch_attention_mask, batch_label_st, batch_label_ed = [], [], [], []\n",
    "\n",
    "    batch_input_ids = torch.cat([torch.cat([x[0]['input_ids'], \n",
    "                       torch.LongTensor([tokenizer.pad_token_id]*(max_len - l))], 0).unsqueeze(0) for x, l in zip(batch, lengths)], 0)\n",
    "    batch_attention_mask = torch.cat([torch.cat([x[0]['attention_mask'], \n",
    "                       torch.Tensor([0]*(max_len - l))], 0).unsqueeze(0) for x, l in zip(batch, lengths)], 0)\n",
    "    batch_label_st = torch.cat([torch.cat([x[1], \n",
    "                       torch.LongTensor([0]*(max_len - l))], 0).unsqueeze(0) for x, l in zip(batch, lengths)], 0)\n",
    "    batch_label_ed = torch.cat([torch.cat([x[2], \n",
    "                       torch.LongTensor([0]*(max_len - l))], 0).unsqueeze(0) for x, l in zip(batch, lengths)], 0)\n",
    "    return {'input_ids': batch_input_ids, 'attention_mask': batch_attention_mask}, batch_label_st, batch_label_ed\n",
    "\n",
    "def collate_function(samples):\n",
    "    c_inputs, c_st, c_ed = padding([x[0] for x in samples])\n",
    "    d_inputs, d_st, d_ed = padding([x[1] for x in samples])\n",
    "    return [c_inputs, c_st, c_ed], [d_inputs, d_st, d_ed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2222879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class relation_model(nn.Module):\n",
    "    def __init__(self, dims = 512, drop_rate = 0):\n",
    "        super().__init__()\n",
    "        self.LM = AutoModel.from_pretrained(model_name, \n",
    "                                           attention_probs_dropout_prob = 0,\n",
    "                                           hidden_dropout_prob = 0,\n",
    "                                           output_hidden_states = True)\n",
    "#         self.LM.encoder.layer = nn.ModuleList([x for i, x in enumerate(self.LM.encoder.layer) if i < 22])\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        self.dims = dims\n",
    "        self.section_embedding = nn.Embedding(2, self.dims)\n",
    "        self.section_layer = nn.Linear(self.LM.config.hidden_size, self.dims, bias = False)\n",
    "        self.summary_layer = nn.Sequential(nn.Mish(), nn.LayerNorm(self.dims))      \n",
    "        \n",
    "        self.summary_encoder = nn.ModuleList()\n",
    "        for i in range(2):\n",
    "            self.summary_encoder.append(nn.TransformerEncoderLayer(d_model = self.dims, nhead = 8,\n",
    "                                                                      dim_feedforward = self.dims*4,\n",
    "                                                                      dropout = drop_rate,\n",
    "                                                                      batch_first = True))     \n",
    "        \n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.Linear(self.dims, 2), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, c_in, d_in):\n",
    "        hidden_c = self.LM(**c_in).last_hidden_state\n",
    "        hidden_d = self.LM(**d_in).last_hidden_state\n",
    "        hidden = torch.cat([hidden_c, hidden_d], 1)\n",
    "\n",
    "        section = torch.LongTensor([0]*hidden_c.shape[1] + [1]*hidden_d.shape[1]).to(hidden.device)\n",
    "        hidden = self.summary_layer(self.section_layer(hidden) + self.section_embedding(section))\n",
    "        \n",
    "        mask = 1 - torch.cat([c_in['attention_mask'], d_in['attention_mask']], 1)\n",
    "        for i in range(2):\n",
    "            hidden = self.summary_encoder[i](hidden, src_key_padding_mask = mask.bool())\n",
    "\n",
    "        probs = self.output_layer(hidden)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136f4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def train_one_epoch(alpha = 1):\n",
    "    model.train()\n",
    "    running = []\n",
    "    for i, (c_inputs, d_inputs) in enumerate(tqdm(tr_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        c_in = {k:v.to(device) for k,v in c_inputs[0].items()}\n",
    "        c_st, c_ed = c_inputs[1].to(device), c_inputs[2].to(device)\n",
    "        d_in = {k:v.to(device) for k,v in d_inputs[0].items()}\n",
    "        d_st, d_ed = d_inputs[1].to(device), d_inputs[2].to(device)\n",
    "        st_label = torch.cat([c_st, d_st], 1)\n",
    "        ed_label = torch.cat([c_ed, d_ed], 1)\n",
    "        mask = torch.cat([c_in['attention_mask'], d_in['attention_mask']], 1)\n",
    "\n",
    "        probs = model(c_in, d_in)\n",
    "        loss1 = -(st_label*probs[:, :, 0].log() + (1 - st_label)*(1 - probs[:, :, 0]).log())\n",
    "        loss2 = -(ed_label*probs[:, :, 1].log() + (1 - ed_label)*(1 - probs[:, :, 1]).log())\n",
    "        w1 = alpha*st_label + (1 - st_label)\n",
    "        w2 = alpha*ed_label + (1 - ed_label)\n",
    "        loss1 = (loss1*mask*w1).sum()/(mask*w1).sum()\n",
    "        loss2 = (loss2*mask*w2).sum()/(mask*w2).sum()\n",
    "        loss = 0.5*loss1 + 0.5*loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        running.append(loss.item())\n",
    "        \n",
    "        if (i % 1000 == 0)&(i > 0):\n",
    "            print(np.mean(running))\n",
    "    \n",
    "    loss_tr = np.mean(running)\n",
    "    return loss_tr\n",
    "\n",
    "def thres_search(y, p):\n",
    "    auc = roc_auc_score(y, p)\n",
    "    f1_table = []\n",
    "    thres_range = np.arange(0.1, 0.9, 0.02)\n",
    "    for thres in thres_range:\n",
    "        f1 = f1_score(y, p > thres)\n",
    "        f1_table.append([thres, f1])\n",
    "    f1_table = np.array(f1_table)\n",
    "    best_thres = thres_range[f1_table[:, -1].argmax(-1)]\n",
    "    f1 = f1_score(y, p > best_thres)\n",
    "    precision = precision_score(y, p > best_thres)\n",
    "    recall = recall_score(y, p > best_thres)\n",
    "    return best_thres, [auc, f1, precision ,recall]\n",
    "\n",
    "def validation(alpha = 1):\n",
    "    model.eval()\n",
    "    probs_val = []\n",
    "    loss_val = []\n",
    "    st_label_val = []\n",
    "    ed_label_val = []\n",
    "    for i, (c_inputs, d_inputs) in enumerate(tqdm(val_loader)):\n",
    "\n",
    "        c_in = {k:v.to(device) for k,v in c_inputs[0].items()}\n",
    "        c_st, c_ed = c_inputs[1].to(device), c_inputs[2].to(device)\n",
    "        d_in = {k:v.to(device) for k,v in d_inputs[0].items()}\n",
    "        d_st, d_ed = d_inputs[1].to(device), d_inputs[2].to(device)\n",
    "        st_label = torch.cat([c_st, d_st], 1)\n",
    "        ed_label = torch.cat([c_ed, d_ed], 1)\n",
    "        mask = torch.cat([c_in['attention_mask'], d_in['attention_mask']], 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probs = model(c_in, d_in)\n",
    "\n",
    "        loss1 = -(st_label*probs[:, :, 0].log() + (1 - st_label)*(1 - probs[:, :, 0]).log())\n",
    "        loss2 = -(ed_label*probs[:, :, 1].log() + (1 - ed_label)*(1 - probs[:, :, 1]).log())\n",
    "        w1 = alpha*st_label + (1 - st_label)\n",
    "        w2 = alpha*ed_label + (1 - ed_label)\n",
    "        loss1 = (loss1*mask*w1).sum()/(mask*w1).sum()\n",
    "        loss2 = (loss2*mask*w2).sum()/(mask*w2).sum()\n",
    "        loss = 0.5*loss1 + 0.5*loss2\n",
    "        loss_val.append(loss.cpu())\n",
    "        \n",
    "        probs_val.append(probs[mask == 1].cpu())\n",
    "        st_label_val.append(st_label[mask == 1].cpu())\n",
    "        ed_label_val.append(ed_label[mask == 1].cpu())\n",
    "\n",
    "    probs_val = torch.cat(probs_val,0)\n",
    "    st_label_val = torch.cat(st_label_val,0)\n",
    "    ed_label_val = torch.cat(ed_label_val,0)\n",
    "    loss_val = np.mean(loss_val)\n",
    "\n",
    "    st_thres, st_metrics = thres_search(st_label_val, probs_val[:, 0])\n",
    "    ed_thres, ed_metrics = thres_search(ed_label_val, probs_val[:, 1])\n",
    "    return loss_val, [st_metrics, ed_metrics], [st_thres, ed_thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c49193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 68046, validation size: 9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48964bd6aef45c795d000617cb8fcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34023 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028544612341680445\n"
     ]
    }
   ],
   "source": [
    "f = 2\n",
    "val_pid = np.load(output_dir + f'val_pid_{f}.npy')\n",
    "tr_pid = np.load(output_dir + f'tr_pid_{f}.npy')\n",
    "\n",
    "print(f'Training size: {len(tr_id)}, validation size: {len(val_pid)}')\n",
    "\n",
    "tr_data = RelationData(tr_pid)\n",
    "val_data = RelationData(val_pid)\n",
    "tr_loader = DataLoader(tr_data, batch_size = 2, shuffle = True, collate_fn = collate_function)\n",
    "val_loader = DataLoader(val_data, batch_size = 8, shuffle = False, collate_fn = collate_function)\n",
    "\n",
    "\n",
    "seedEverything(616)\n",
    "\n",
    "model = relation_model().to(device)\n",
    "optimizer = AdamP([{'params': [w for name, w in model.named_parameters() if ('LM' not in name)], \n",
    "                    'lr': 5e-5},\n",
    "                   {'params': [w for name, w in model.named_parameters() if ('LM' in name)], \n",
    "                    'lr': 5e-6}],\n",
    "                  betas=(0.9, 0.999), weight_decay=1e-1)\n",
    "\n",
    "tolerance = 0\n",
    "best_f1 = 0\n",
    "metrics_log = {}\n",
    "for i in range(5):\n",
    "    loss_tr = train_one_epoch()\n",
    "    loss_val, metrics, thres = validation()\n",
    "    f1 = np.mean([x[1] for x in metrics])\n",
    "    print(loss_tr, loss_val, np.array(metrics).mean(0))\n",
    "    metrics_log[i] = [loss_tr, loss_val, np.array(metrics).mean(0).tolist(), thres]\n",
    "\n",
    "    with open(output_dir + f'training_log_{f}.pk5', 'wb') as f:\n",
    "        pickle5.dump(metrics_log, f)\n",
    "\n",
    "    if best_f1 < f1:\n",
    "        best_f1 = deepcopy(f1)\n",
    "        best_metrics = deepcopy(metrics)\n",
    "        best_model = deepcopy(model)\n",
    "        torch.save(best_model.state_dict(), output_dir + f'{model_type}_{f}.pt')\n",
    "        tolerance = 0\n",
    "    else:\n",
    "        tolerance += 1\n",
    "\n",
    "    if tolerance > 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
